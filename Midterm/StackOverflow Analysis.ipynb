{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/questions?tagged=python;pandas&page=1&pagesize=100&site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "#print(raw_data)\n",
    "\n",
    "d={}\n",
    "for key in raw_data['items']:\n",
    "    d[key['question_id']]=key\n",
    "    \n",
    "import json\n",
    "with open('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/UserData/data.json', 'w') as outfile:\n",
    "    json.dump(d,outfile)\n",
    "\n",
    "\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/questions/no-answers?tagged=python;pandas&page=1&pagesize=100&site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "#print(raw_data)\n",
    "\n",
    "#Dictionary to hold question_id and link\n",
    "d={}\n",
    "for data in raw_data['items']:\n",
    "    d[data['question_id']]=data\n",
    "    \n",
    "import json\n",
    "with open('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/Questions/unanswered_questions.json', 'w') as outfile:\n",
    "    json.dump(d,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Questions based on user Badges containing keywords Pandas and Python\n",
      "Badges   Question       \n",
      "175      How do I round datetime column to nearest quarter hour\n",
      "511      HDF5 - concurrency, compression &amp; I/O performance\n",
      "149      Finding the largest N integrals in a time series with Python\n",
      "77       Pandas performance varies between mac and linux\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8eb3195c272c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\mital\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    222\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    223\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mital\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mital\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   5229\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5231\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5233\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mital\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   5268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5270\u001b[1;33m             raise ValueError('If using all scalar values, you must pass'\n\u001b[0m\u001b[0;32m   5271\u001b[0m                              ' an index')\n\u001b[0;32m   5272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import glob\n",
    "\n",
    "#declare a set to hold all the user ids\n",
    "user_ids=set()\n",
    "files=glob.glob('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/UserData/*.json')   \n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        data=f.read()\n",
    "        user_data=json.loads(data)\n",
    "        for key in user_data:\n",
    "            #read all the keys in json and assign it to set \n",
    "            user_ids.add(user_data[key]['owner']['user_id'])\n",
    "            \n",
    "#convert the set to string\n",
    "users=str(user_ids)\n",
    "#make it a string of ids seperated by comma\n",
    "users = users.replace(\", \",\";\")\n",
    "users = users.replace(\"{\",\"\")\n",
    "users = users.replace(\"}\",\"\")\n",
    "users = users.replace(\"'\",\"\")\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/users/\"+users+\"?site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "\n",
    "#Dictionary to hold user_ids and their badge\n",
    "d={}\n",
    "for data in raw_data['items']:\n",
    "    d[str(data['user_id'])]=data['badge_counts']\n",
    "#print(d)\n",
    "#Dictionary to hold user_ids and sum of badge counts\n",
    "data={}   \n",
    "for key in d:\n",
    "    data[key]=d[key]['gold']+d[key]['silver']+d[key]['bronze']\n",
    "#print(data)    \n",
    "sorted_data=sorted(data.items(), key=lambda x: (-x[1], x[0]))[:5]  \n",
    "\n",
    "questions_data={}\n",
    "for d in user_data:\n",
    "    questions_data[str(user_data[d]['owner']['user_id'])]=user_data[d]['title']\n",
    "#print(questions_data.keys())\n",
    "\n",
    "with open('user_data.json', 'w') as outfile:\n",
    "    json.dump(data,outfile)\n",
    "final_data=dict(sorted_data)\n",
    "#print(final_data.keys())\n",
    "final={}        \n",
    "for key in final_data.keys():\n",
    "    if key in questions_data.keys():\n",
    "        final[final_data[key]]=questions_data[key]\n",
    "print('Top Questions based on user Badges containing keywords Pandas and Python')        \n",
    "print (\"{:<8} {:<15}\".format('Badges','Question'))\n",
    "for k in final:\n",
    "    print (\"{:<8} {:<15}\".format(k, final[k]))\n",
    "\n",
    "plt.barh(range(len(final)), final.keys(),alpha=0.5)\n",
    "plt.yticks(range(len(final)), final.values())\n",
    "plt.xlabel('Badges')\n",
    "plt.title('Top Questions based on user Badges containing keywords Pandas and Python')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------+-------------------------+\n",
      "|        Question         |           ID            |          LINK           |\n",
      "+=========================+=========================+=========================+\n",
      "| Login Log Off analysis  | 40350907                | http://stackoverflow.co |\n",
      "| Python Pandas           |                         | m/questions/40350907/lo |\n",
      "| Timelining              |                         | gin-log-off-analysis-   |\n",
      "|                         |                         | python-pandas-          |\n",
      "|                         |                         | timelining              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Cross join time series  | 40073279                | http://stackoverflow.co |\n",
      "| dataset applying asof   |                         | m/questions/40073279/cr |\n",
      "| criteria on time while  |                         | oss-join-time-series-   |\n",
      "| limiting number of rows |                         | dataset-applying-asof-  |\n",
      "|                         |                         | criteria-on-time-while- |\n",
      "|                         |                         | limiting-num            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas list cursor      | 40120931                | http://stackoverflow.co |\n",
      "| error                   |                         | m/questions/40120931/pa |\n",
      "|                         |                         | ndas-list-cursor-error  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Calculating Average     | 40256338                | http://stackoverflow.co |\n",
      "| True Range (ATR) on     |                         | m/questions/40256338/ca |\n",
      "| OHLC data with Python   |                         | lculating-average-true- |\n",
      "|                         |                         | range-atr-on-ohlc-data- |\n",
      "|                         |                         | with-python             |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas.DataFrame.max()  | 40160101                | http://stackoverflow.co |\n",
      "| command does not return |                         | m/questions/40160101/pa |\n",
      "| correct values          |                         | ndas-dataframe-max-     |\n",
      "|                         |                         | command-does-not-       |\n",
      "|                         |                         | return-correct-values   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Grouping Tweets by      | 40090254                | http://stackoverflow.co |\n",
      "| Half-Hour, Hour, and    |                         | m/questions/40090254/gr |\n",
      "| Day in Pandas Dataframe |                         | ouping-tweets-by-half-  |\n",
      "|                         |                         | hour-hour-and-day-in-   |\n",
      "|                         |                         | pandas-dataframe        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| matplotlib gives a      | 40079155                | http://stackoverflow.co |\n",
      "| ValueError: could not   |                         | m/questions/40079155/ma |\n",
      "| convert string to       |                         | tplotlib-gives-a-       |\n",
      "| float:                  |                         | valueerror-could-not-   |\n",
      "|                         |                         | convert-string-to-float |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| accelerating the data   | 40117874                | http://stackoverflow.co |\n",
      "| generation process      |                         | m/questions/40117874/ac |\n",
      "|                         |                         | celerating-the-data-    |\n",
      "|                         |                         | generation-process      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Changes in data frame   | 40294115                | http://stackoverflow.co |\n",
      "| not reflected in csv    |                         | m/questions/40294115/ch |\n",
      "| output                  |                         | anges-in-data-frame-    |\n",
      "|                         |                         | not-reflected-in-csv-   |\n",
      "|                         |                         | output                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Looking for a module to | 40174033                | http://stackoverflow.co |\n",
      "| read and manipulate     |                         | m/questions/40174033/lo |\n",
      "| .fcs files in python    |                         | oking-for-a-module-to-  |\n",
      "|                         |                         | read-and-manipulate-    |\n",
      "|                         |                         | fcs-files-in-python     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Dataframe with many     | 40180371                | http://stackoverflow.co |\n",
      "| punctuation marks to    |                         | m/questions/40180371/da |\n",
      "| csv using python3       |                         | taframe-with-many-      |\n",
      "|                         |                         | punctuation-marks-to-   |\n",
      "|                         |                         | csv-using-python3       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Index pandas df, find   | 40050201                | http://stackoverflow.co |\n",
      "| match based on column   |                         | m/questions/40050201/in |\n",
      "| D, E, F, write values   |                         | dex-pandas-df-find-     |\n",
      "| from column C to column |                         | match-based-on-column-  |\n",
      "| B                       |                         | d-e-f-write-values-     |\n",
      "|                         |                         | from-column-c           |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Dataframe - Sum Arrays  | 40113593                | http://stackoverflow.co |\n",
      "| in Cell - Memory Issue  |                         | m/questions/40113593/da |\n",
      "|                         |                         | taframe-sum-arrays-in-  |\n",
      "|                         |                         | cell-memory-issue       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How do I freeze a       | 40348099                | http://stackoverflow.co |\n",
      "| pandas dataframe column |                         | m/questions/40348099/ho |\n",
      "| when subsetting the     |                         | w-do-i-freeze-a-pandas- |\n",
      "| data frame?             |                         | dataframe-column-when-  |\n",
      "|                         |                         | subsetting-the-data-    |\n",
      "|                         |                         | frame                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Setting HTML attributes | 40285745                | http://stackoverflow.co |\n",
      "| with Pandas styler for  |                         | m/questions/40285745/se |\n",
      "| displaying dataframes   |                         | tting-html-attributes-  |\n",
      "|                         |                         | with-pandas-styler-for- |\n",
      "|                         |                         | displaying-dataframes   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How is                  | 40351118                | http://stackoverflow.co |\n",
      "| scipy.stats.entropy     |                         | m/questions/40351118/ho |\n",
      "| calculated?             |                         | w-is-scipy-stats-       |\n",
      "|                         |                         | entropy-calculated      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas date overlap     | 40157608                | http://stackoverflow.co |\n",
      "|                         |                         | m/questions/40157608/pa |\n",
      "|                         |                         | ndas-date-overlap       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| get_dummies() throws    | 40079982                | http://stackoverflow.co |\n",
      "| Memory Error            |                         | m/questions/40079982/ge |\n",
      "|                         |                         | t-dummies-throws-       |\n",
      "|                         |                         | memory-error            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Spark Streaming: From   | 40201868                | http://stackoverflow.co |\n",
      "| DStream to Pandas       |                         | m/questions/40201868/sp |\n",
      "| Dataframe               |                         | ark-streaming-from-     |\n",
      "|                         |                         | dstream-to-pandas-      |\n",
      "|                         |                         | dataframe               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| What is the equivalent  | 40212401                | http://stackoverflow.co |\n",
      "| for Iterrows in Python  |                         | m/questions/40212401/wh |\n",
      "| 3.5                     |                         | at-is-the-equivalent-   |\n",
      "|                         |                         | for-iterrows-in-        |\n",
      "|                         |                         | python-3-5              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas - improving      | 40279387                | http://stackoverflow.co |\n",
      "| memory usage when       |                         | m/questions/40279387/pa |\n",
      "| loading dumped json in  |                         | ndas-improving-memory-  |\n",
      "| column as dictionaries  |                         | usage-when-loading-     |\n",
      "|                         |                         | dumped-json-in-column-  |\n",
      "|                         |                         | as-dictionari           |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Can&#39;t import        | 40320013                | http://stackoverflow.co |\n",
      "| sicikit-learn and       |                         | m/questions/40320013/ca |\n",
      "| pandas                  |                         | nt-import-sicikit-      |\n",
      "|                         |                         | learn-and-pandas        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python Pandas --        | 40244094                | http://stackoverflow.co |\n",
      "| Determine if Values in  |                         | m/questions/40244094/py |\n",
      "| Column 0 Are Repeated   |                         | thon-pandas-determine-  |\n",
      "| in Each Subsequent      |                         | if-values-in-           |\n",
      "| Column                  |                         | column-0-are-repeated-  |\n",
      "|                         |                         | in-each-subsequent      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to do context       | 40352406                | http://stackoverflow.co |\n",
      "| dependent data frame    |                         | m/questions/40352406/ho |\n",
      "| merge in python?        |                         | w-to-do-context-        |\n",
      "|                         |                         | dependent-data-frame-   |\n",
      "|                         |                         | merge-in-python         |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| python ggplot cutting   | 40304353                | http://stackoverflow.co |\n",
      "| off microseconds        |                         | m/questions/40304353/py |\n",
      "|                         |                         | thon-ggplot-cutting-    |\n",
      "|                         |                         | off-microseconds        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Change 1*140 dataframe  | 40084676                | http://stackoverflow.co |\n",
      "| to 7*20 dataframe in    |                         | m/questions/40084676/ch |\n",
      "| python pandas           |                         | ange-1140-dataframe-    |\n",
      "|                         |                         | to-720-dataframe-in-    |\n",
      "|                         |                         | python-pandas           |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Prediction of Stock     | 40353695                | http://stackoverflow.co |\n",
      "| Prices using ARIMA      |                         | m/questions/40353695/pr |\n",
      "|                         |                         | ediction-of-stock-      |\n",
      "|                         |                         | prices-using-arima      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to change the data  | 40079794                | http://stackoverflow.co |\n",
      "| types of a column in    |                         | m/questions/40079794/ho |\n",
      "| Pandas when read_csv()  |                         | w-to-change-the-data-   |\n",
      "|                         |                         | types-of-a-column-in-   |\n",
      "|                         |                         | pandas-when-read-csv    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Why do some methods not | 40272942                | http://stackoverflow.co |\n",
      "| have an inplace option? |                         | m/questions/40272942/wh |\n",
      "| [Pandas]                |                         | y-do-some-methods-not-  |\n",
      "|                         |                         | have-an-inplace-option- |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to replace values   | 40089889                | http://stackoverflow.co |\n",
      "| in &#171;groupby&#187;  |                         | m/questions/40089889/ho |\n",
      "| (python) object?        |                         | w-to-replace-values-in- |\n",
      "|                         |                         | groupby-python-object   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| deleting pandas         | 40080019                | http://stackoverflow.co |\n",
      "| dataframe column        |                         | m/questions/40080019/de |\n",
      "|                         |                         | leting-pandas-          |\n",
      "|                         |                         | dataframe-column        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Aggregating on 5 minute | 40341213                | http://stackoverflow.co |\n",
      "| windows in pyspark      |                         | m/questions/40341213/ag |\n",
      "|                         |                         | gregating-on-5-minute-  |\n",
      "|                         |                         | windows-in-pyspark      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Return excel file from  | 40269047                | http://stackoverflow.co |\n",
      "| pandas with flask       |                         | m/questions/40269047/re |\n",
      "|                         |                         | turn-excel-file-from-   |\n",
      "|                         |                         | pandas-with-flask       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| CSV file Parsing issue  | 40041222                | http://stackoverflow.co |\n",
      "| because of unintended   |                         | m/questions/40041222/cs |\n",
      "| characters              |                         | v-file-parsing-issue-   |\n",
      "| (CParserError: Error    |                         | because-of-unintended-  |\n",
      "| tokenizing data) in     |                         | characters-             |\n",
      "| Pandas                  |                         | cparsererror-error-tok  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Appending SQLite /      | 40323411                | http://stackoverflow.co |\n",
      "| MySQL table with Python |                         | m/questions/40323411/ap |\n",
      "| Pandas column           |                         | pending-sqlite-mysql-   |\n",
      "|                         |                         | table-with-python-      |\n",
      "|                         |                         | pandas-column           |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Computing Aggregated    | 40211090                | http://stackoverflow.co |\n",
      "| Stats on Pandas         |                         | m/questions/40211090/co |\n",
      "|                         |                         | mputing-aggregated-     |\n",
      "|                         |                         | stats-on-pandas         |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas returning empty  | 40270627                | http://stackoverflow.co |\n",
      "| groups in groupby       |                         | m/questions/40270627/pa |\n",
      "|                         |                         | ndas-returning-empty-   |\n",
      "|                         |                         | groups-in-groupby       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| List of diverse lists   | 40346400                | http://stackoverflow.co |\n",
      "| to sorted pandas data   |                         | m/questions/40346400/li |\n",
      "| frame                   |                         | st-of-diverse-lists-to- |\n",
      "|                         |                         | sorted-pandas-data-     |\n",
      "|                         |                         | frame                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas TimeGrouper in   | 40327936                | http://stackoverflow.co |\n",
      "| PySpark                 |                         | m/questions/40327936/pa |\n",
      "|                         |                         | ndas-timegrouper-in-    |\n",
      "|                         |                         | pyspark                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Writing Pandas&#39;     | 40332319                | http://stackoverflow.co |\n",
      "| dataframe into SQL      |                         | m/questions/40332319/wr |\n",
      "| Servet table            |                         | iting-pandas-dataframe- |\n",
      "|                         |                         | into-sql-servet-table   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas parallel do not  | 40142265                | http://stackoverflow.co |\n",
      "| stop                    |                         | m/questions/40142265/pa |\n",
      "|                         |                         | ndas-parallel-do-not-   |\n",
      "|                         |                         | stop                    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to merge time       | 40196682                | http://stackoverflow.co |\n",
      "| series data frames in   |                         | m/questions/40196682/ho |\n",
      "| Pandas with asymmetric  |                         | w-to-merge-time-series- |\n",
      "| data?                   |                         | data-frames-in-pandas-  |\n",
      "|                         |                         | with-asymmetric-data    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Matrix vector product   | 40241047                | http://stackoverflow.co |\n",
      "| of panel and dataframe  |                         | m/questions/40241047/ma |\n",
      "| without loop            |                         | trix-vector-product-of- |\n",
      "|                         |                         | panel-and-dataframe-    |\n",
      "|                         |                         | without-loop            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to fill missing     | 40327963                | http://stackoverflow.co |\n",
      "| Timestamp values in     |                         | m/questions/40327963/ho |\n",
      "| padas data frame        |                         | w-to-fill-missing-      |\n",
      "|                         |                         | timestamp-values-in-    |\n",
      "|                         |                         | padas-data-frame        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas - Loc            | 40119416                | http://stackoverflow.co |\n",
      "| w/categories            |                         | m/questions/40119416/pa |\n",
      "|                         |                         | ndas-loc-w-categories   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pickling error in       | 40102285                | http://stackoverflow.co |\n",
      "| passing Pandas          |                         | m/questions/40102285/pi |\n",
      "| DataFrame to method     |                         | ckling-error-in-        |\n",
      "| call in multi           |                         | passing-pandas-         |\n",
      "| processing              |                         | dataframe-to-method-    |\n",
      "|                         |                         | call-in-multi-          |\n",
      "|                         |                         | processing              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| building a dataframe    | 40139405                | http://stackoverflow.co |\n",
      "| from grouped data in    |                         | m/questions/40139405/bu |\n",
      "| pandas                  |                         | ilding-a-dataframe-     |\n",
      "|                         |                         | from-grouped-data-in-   |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python - using py2exe   | 40343894                | http://stackoverflow.co |\n",
      "| with pandas             |                         | m/questions/40343894/py |\n",
      "|                         |                         | thon-using-py2exe-with- |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| PermissionError: [Errno | 40337482                | http://stackoverflow.co |\n",
      "| 13] Permission denied:  |                         | m/questions/40337482/pe |\n",
      "| &#39;pubmed_output&#39; |                         | rmissionerror-          |\n",
      "| (writing to csv file)   |                         | errno-13-permission-    |\n",
      "|                         |                         | denied-pubmed-output-   |\n",
      "|                         |                         | writing-to-csv-f        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| A special case of       | 40236907                | http://stackoverflow.co |\n",
      "| duplicates              |                         | m/questions/40236907/a- |\n",
      "|                         |                         | special-case-of-        |\n",
      "|                         |                         | duplicates              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Backtesting with Data   | 37516730                | http://stackoverflow.co |\n",
      "|                         |                         | m/questions/37516730/ba |\n",
      "|                         |                         | cktesting-with-data     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to import Pandas    | 40070051                | http://stackoverflow.co |\n",
      "| library in Python?      |                         | m/questions/40070051/ho |\n",
      "|                         |                         | w-to-import-pandas-     |\n",
      "|                         |                         | library-in-python       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Scikit Learn Find most  | 40157978                | http://stackoverflow.co |\n",
      "| representative words by |                         | m/questions/40157978/sc |\n",
      "| TFIDF, in subset of     |                         | ikit-learn-find-most-   |\n",
      "| entire corpus           |                         | representative-words-   |\n",
      "|                         |                         | by-tfidf-in-subset-of-  |\n",
      "|                         |                         | entire-corpus           |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Apply different         | 40137140                | http://stackoverflow.co |\n",
      "| estimators on data      |                         | m/questions/40137140/ap |\n",
      "| points depending on     |                         | ply-different-          |\n",
      "| which features are      |                         | estimators-on-data-     |\n",
      "| present                 |                         | points-depending-on-    |\n",
      "|                         |                         | which-features-are-     |\n",
      "|                         |                         | presen                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Plotting event density  | 40101519                | http://stackoverflow.co |\n",
      "| in Python with ggplot   |                         | m/questions/40101519/pl |\n",
      "| and pandas              |                         | otting-event-density-   |\n",
      "|                         |                         | in-python-with-ggplot-  |\n",
      "|                         |                         | and-pandas              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| OpenPyxl Module Needed  | 40093352                | http://stackoverflow.co |\n",
      "| For DataFrames?         |                         | m/questions/40093352/op |\n",
      "|                         |                         | enpyxl-module-needed-   |\n",
      "|                         |                         | for-dataframes          |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Rolling Mean with       | 40262195                | http://stackoverflow.co |\n",
      "| Groupby object in       |                         | m/questions/40262195/ro |\n",
      "| Pandas returns null     |                         | lling-mean-with-        |\n",
      "|                         |                         | groupby-object-in-      |\n",
      "|                         |                         | pandas-returns-null     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python - Using Pandas   | 40274850                | http://stackoverflow.co |\n",
      "| with a Mechanize and    |                         | m/questions/40274850/py |\n",
      "| BS4 Response            |                         | thon-using-pandas-with- |\n",
      "|                         |                         | a-mechanize-and-        |\n",
      "|                         |                         | bs4-response            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| KeyError:               | 40075230                | http://stackoverflow.co |\n",
      "| numpy.datetime64 after  |                         | m/questions/40075230/ke |\n",
      "| changing only the month |                         | yerror-numpy-           |\n",
      "| of a datetime (Zipline) |                         | datetime64-after-       |\n",
      "|                         |                         | changing-only-the-      |\n",
      "|                         |                         | month-of-a-datetime-    |\n",
      "|                         |                         | zipline                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python: the pandas      | 40225224                | http://stackoverflow.co |\n",
      "| dataframe function keep |                         | m/questions/40225224/py |\n",
      "| thinking the same       |                         | thon-the-pandas-        |\n",
      "| dataframe has different |                         | dataframe-function-     |\n",
      "| dimensions              |                         | keep-thinking-the-same- |\n",
      "|                         |                         | dataframe-has-diffe     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Setting low_memory to   | 40084589                | http://stackoverflow.co |\n",
      "| false while reading a   |                         | m/questions/40084589/se |\n",
      "| mixed dtype 2.5GB csv   |                         | tting-low-memory-to-    |\n",
      "| file using Pandas is    |                         | false-while-reading-a-  |\n",
      "| not working             |                         | mixed-dtype-2-5gb-csv-  |\n",
      "|                         |                         | file-using-pan          |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas updating column  | 40114807                | http://stackoverflow.co |\n",
      "| value using isin and    |                         | m/questions/40114807/pa |\n",
      "| loc                     |                         | ndas-updating-column-   |\n",
      "|                         |                         | value-using-isin-and-   |\n",
      "|                         |                         | loc                     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| matplotlib and pandas:  | 40202331                | http://stackoverflow.co |\n",
      "| Add colors to           |                         | m/questions/40202331/ma |\n",
      "| individual plot points  |                         | tplotlib-and-pandas-    |\n",
      "| with a map              |                         | add-colors-to-          |\n",
      "|                         |                         | individual-plot-points- |\n",
      "|                         |                         | with-a-map              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Merge CountVectorizer   | 40162277                | http://stackoverflow.co |\n",
      "| output from 4 text      |                         | m/questions/40162277/me |\n",
      "| columns back into one   |                         | rge-countvectorizer-    |\n",
      "| dataset                 |                         | output-from-4-text-     |\n",
      "|                         |                         | columns-back-into-one-  |\n",
      "|                         |                         | dataset                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Login Time Wheel Python | 40352607                | http://stackoverflow.co |\n",
      "|                         |                         | m/questions/40352607/lo |\n",
      "|                         |                         | gin-time-wheel-python   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How do I create a class | 40224038                | http://stackoverflow.co |\n",
      "| that merges and returns |                         | m/questions/40224038/ho |\n",
      "| a dataframe, but        |                         | w-do-i-create-a-class-  |\n",
      "| inherits from another   |                         | that-merges-and-        |\n",
      "| class?                  |                         | returns-a-dataframe-    |\n",
      "|                         |                         | but-inherits-from-a     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas dataframe series | 40235384                | http://stackoverflow.co |\n",
      "| has bengali values. How |                         | m/questions/40235384/pa |\n",
      "| to include it in a bar  |                         | ndas-dataframe-series-  |\n",
      "| chart xticks?           |                         | has-bengali-values-how- |\n",
      "|                         |                         | to-include-it-in-a-bar- |\n",
      "|                         |                         | chart-xti               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas performance      | 40345556                | http://stackoverflow.co |\n",
      "| varies between mac and  |                         | m/questions/40345556/pa |\n",
      "| linux                   |                         | ndas-performance-       |\n",
      "|                         |                         | varies-between-mac-and- |\n",
      "|                         |                         | linux                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Print Knn prediction    | 40332336                | http://stackoverflow.co |\n",
      "| alongside id            |                         | m/questions/40332336/pr |\n",
      "|                         |                         | int-knn-prediction-     |\n",
      "|                         |                         | alongside-id            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Getting error KeyError: | 40191650                | http://stackoverflow.co |\n",
      "| &#39;retweeted_status&# |                         | m/questions/40191650/ge |\n",
      "| 39; while reading       |                         | tting-error-keyerror-   |\n",
      "| nested json document    |                         | retweeted-status-while- |\n",
      "|                         |                         | reading-nested-json-    |\n",
      "|                         |                         | document                |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| parallel processing     | 40114305                | http://stackoverflow.co |\n",
      "| with dataframes python  |                         | m/questions/40114305/pa |\n",
      "|                         |                         | rallel-processing-with- |\n",
      "|                         |                         | dataframes-python       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas - Function to    | 40157485                | http://stackoverflow.co |\n",
      "| have to tell if event   |                         | m/questions/40157485/pa |\n",
      "| happened on consecutive |                         | ndas-function-to-have-  |\n",
      "| days                    |                         | to-tell-if-event-       |\n",
      "|                         |                         | happened-on-            |\n",
      "|                         |                         | consecutive-days        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas DF to Oracle DB  | 40209731                | http://stackoverflow.co |\n",
      "|                         |                         | m/questions/40209731/pa |\n",
      "|                         |                         | ndas-df-to-oracle-db    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Merge 2 data streams    | 40093774                | http://stackoverflow.co |\n",
      "| into 1 after using      |                         | m/questions/40093774/me |\n",
      "| pandas                  |                         | rge-2-data-streams-     |\n",
      "|                         |                         | into-1-after-using-     |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to add a bolean     | 40302071                | http://stackoverflow.co |\n",
      "| series to a new column  |                         | m/questions/40302071/ho |\n",
      "| in df2 IF multiple      |                         | w-to-add-a-bolean-      |\n",
      "| conditions in df1 are   |                         | series-to-a-new-column- |\n",
      "| met (incl. DATETIME)?   |                         | in-df2-if-multiple-     |\n",
      "|                         |                         | conditions-in-df1       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python sklearn          | 32383381                | http://stackoverflow.co |\n",
      "| preprocessing package   |                         | m/questions/32383381/py |\n",
      "| returns error:          |                         | thon-sklearn-           |\n",
      "| ValueError: invalid     |                         | preprocessing-package-  |\n",
      "| literal for float()     |                         | returns-error-          |\n",
      "|                         |                         | valueerror-invalid-     |\n",
      "|                         |                         | literal                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python count the        | 40340873                | http://stackoverflow.co |\n",
      "| frequency value -       |                         | m/questions/40340873/py |\n",
      "| create data structure   |                         | thon-count-the-         |\n",
      "|                         |                         | frequency-value-create- |\n",
      "|                         |                         | data-structure          |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python: Pandas, Text    | 40117799                | http://stackoverflow.co |\n",
      "| File to DataFrame       |                         | m/questions/40117799/py |\n",
      "|                         |                         | thon-pandas-text-file-  |\n",
      "|                         |                         | to-dataframe            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Individual/Population   | 40099762                | http://stackoverflow.co |\n",
      "| selection in Genetic    |                         | m/questions/40099762/in |\n",
      "| Algorithm using Pandas  |                         | dividual-population-    |\n",
      "|                         |                         | selection-in-genetic-   |\n",
      "|                         |                         | algorithm-using-pandas  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Using functions from    | 40195803                | http://stackoverflow.co |\n",
      "| modules in pandas       |                         | m/questions/40195803/us |\n",
      "| dataframe               |                         | ing-functions-from-     |\n",
      "|                         |                         | modules-in-pandas-      |\n",
      "|                         |                         | dataframe               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| what is a verifiable    | 40213095                | http://stackoverflow.co |\n",
      "| example of how to       |                         | m/questions/40213095/wh |\n",
      "| trigger a `is_copy`     |                         | at-is-a-verifiable-     |\n",
      "| flag?                   |                         | example-of-how-to-      |\n",
      "|                         |                         | trigger-a-is-copy-flag  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Sorting on multiple     | 40113979                | http://stackoverflow.co |\n",
      "| levels in pandas pivot  |                         | m/questions/40113979/so |\n",
      "| table while preserving  |                         | rting-on-multiple-      |\n",
      "| subtotals               |                         | levels-in-pandas-pivot- |\n",
      "|                         |                         | table-while-preserving- |\n",
      "|                         |                         | subtotals               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Handling unknown values | 40321232                | http://stackoverflow.co |\n",
      "| for label encoding      |                         | m/questions/40321232/ha |\n",
      "|                         |                         | ndling-unknown-values-  |\n",
      "|                         |                         | for-label-encoding      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Find pre/post-decessor  | 40105090                | http://stackoverflow.co |\n",
      "| in pandas for each      |                         | m/questions/40105090/fi |\n",
      "| group                   |                         | nd-pre-post-decessor-   |\n",
      "|                         |                         | in-pandas-for-each-     |\n",
      "|                         |                         | group                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to plot on box plot | 40349226                | http://stackoverflow.co |\n",
      "| 2 data from different   |                         | m/questions/40349226/ho |\n",
      "| data frama - Python     |                         | w-to-plot-on-box-       |\n",
      "|                         |                         | plot-2-data-from-       |\n",
      "|                         |                         | different-data-frama-   |\n",
      "|                         |                         | python                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| dataframe.describe()    | 40347689                | http://stackoverflow.co |\n",
      "| suppress scientific     |                         | m/questions/40347689/da |\n",
      "| notation                |                         | taframe-describe-       |\n",
      "|                         |                         | suppress-scientific-    |\n",
      "|                         |                         | notation                |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| trimming a pandas       | 40083816                | http://stackoverflow.co |\n",
      "| column with regex       |                         | m/questions/40083816/tr |\n",
      "|                         |                         | imming-a-pandas-column- |\n",
      "|                         |                         | with-regex              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas and GGPlot       | 40069001                | http://stackoverflow.co |\n",
      "| &#39;Could not compare  |                         | m/questions/40069001/pa |\n",
      "| [__index__] with block  |                         | ndas-and-ggplot-could-  |\n",
      "| values&#39;, even after |                         | not-compare-index-with- |\n",
      "| df.fillna(0)            |                         | block-values-even-after |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas: compare two     | 40085447                | http://stackoverflow.co |\n",
      "| dataframe and intersect |                         | m/questions/40085447/pa |\n",
      "| that                    |                         | ndas-compare-two-       |\n",
      "|                         |                         | dataframe-and-          |\n",
      "|                         |                         | intersect-that          |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| cant groupby on certain | 40125654                | http://stackoverflow.co |\n",
      "| column after merging 2  |                         | m/questions/40125654/ca |\n",
      "| dataframes in python    |                         | nt-groupby-on-certain-  |\n",
      "|                         |                         | column-after-           |\n",
      "|                         |                         | merging-2-dataframes-   |\n",
      "|                         |                         | in-python               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas concat :         | 40095906                | http://stackoverflow.co |\n",
      "| Incorrect total length  |                         | m/questions/40095906/pa |\n",
      "| after dataframes are    |                         | ndas-concat-incorrect-  |\n",
      "| concatenated            |                         | total-length-after-     |\n",
      "|                         |                         | dataframes-are-         |\n",
      "|                         |                         | concatenated            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| error concatenating     | 40206877                | http://stackoverflow.co |\n",
      "| multiindex pandas       |                         | m/questions/40206877/er |\n",
      "| dataframes              |                         | ror-concatenating-      |\n",
      "| (categorical)           |                         | multiindex-pandas-      |\n",
      "|                         |                         | dataframes-categorical  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Backreference in Pandas | 40353555                | http://stackoverflow.co |\n",
      "| str.replace             |                         | m/questions/40353555/ba |\n",
      "|                         |                         | ckreference-in-pandas-  |\n",
      "|                         |                         | str-replace             |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| ObjectHashTable.get_ite | 40209089                | http://stackoverflow.co |\n",
      "| m (pandas/hashtable.c:1 |                         | m/questions/40209089/ob |\n",
      "| 3115) error in pandas   |                         | jecthashtable-get-item- |\n",
      "| dataframe; issues in    |                         | pandas-                 |\n",
      "| indexing a column       |                         | hashtable-c13115-error- |\n",
      "|                         |                         | in-pandas-dataframe-i   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Brunel API not read     | 40140813                | http://stackoverflow.co |\n",
      "| dataframe?              |                         | m/questions/40140813/br |\n",
      "|                         |                         | unel-api-not-read-      |\n",
      "|                         |                         | dataframe               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Add columns and values  | 40171777                | http://stackoverflow.co |\n",
      "| to pandas DataFrame     |                         | m/questions/40171777/ad |\n",
      "|                         |                         | d-columns-and-values-   |\n",
      "|                         |                         | to-pandas-dataframe     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to remove elements  | 40142766                | http://stackoverflow.co |\n",
      "| from a nested json with |                         | m/questions/40142766/ho |\n",
      "| pandas?                 |                         | w-to-remove-elements-   |\n",
      "|                         |                         | from-a-nested-json-     |\n",
      "|                         |                         | with-pandas             |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Select specific fields  | 40090710                | http://stackoverflow.co |\n",
      "| from nested json data   |                         | m/questions/40090710/se |\n",
      "|                         |                         | lect-specific-fields-   |\n",
      "|                         |                         | from-nested-json-data   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| X Axis label is wrong   | 40180815                | http://stackoverflow.co |\n",
      "| when plotting a Time    |                         | m/questions/40180815/x- |\n",
      "| Series with Plotly and  |                         | axis-label-is-wrong-    |\n",
      "| Pandas                  |                         | when-plotting-a-time-   |\n",
      "|                         |                         | series-with-plotly-and- |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| sshtunnel not working   | 40328324                | http://stackoverflow.co |\n",
      "| in when used in a       |                         | m/questions/40328324/ss |\n",
      "| function                |                         | htunnel-not-working-in- |\n",
      "|                         |                         | when-used-in-a-function |\n",
      "+-------------------------+-------------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "    \n",
    "data_file = open('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/Questions/unanswered_questions.json','r')\n",
    "\n",
    "#read the json file\n",
    "unanswered_questions=json.loads(data_file.read())\n",
    "  \n",
    "import texttable as tt\n",
    "tab = tt.Texttable()\n",
    "header = ['Question','ID','LINK']\n",
    "tab.header(header)\n",
    "for key in unanswered_questions:\n",
    "    row = [unanswered_questions[key]['title'],unanswered_questions[key]['question_id'],unanswered_questions[key]['link']]\n",
    "    tab.add_row(row)\n",
    "s = tab.draw()\n",
    "print(s)\n",
    "\n",
    "id=input('Enter Question ID to search for related answered questions:')\n",
    "print(id)\n",
    "\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/questions/\"+id+\"/related?order=desc&sort=rank&site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "d={}\n",
    "for data in raw_data['items']:\n",
    "    d[data['question_id']]=data\n",
    " \n",
    "\n",
    "with open('answered_questions.json', 'w') as outfile:\n",
    "    json.dump(d,outfile)\n",
    "    \n",
    "data_file = open('answered_questions.json','r')\n",
    "\n",
    "#read the json file\n",
    "answered_questions=json.loads(data_file.read())\n",
    "\n",
    "import texttable as tt\n",
    "tab = tt.Texttable()\n",
    "header = ['Question','ID','LINK']\n",
    "tab.header(header)\n",
    "for key in answered_questions:\n",
    "    row = [answered_questions[key]['title'],answered_questions[key]['question_id'],answered_questions[key]['link']]\n",
    "    tab.add_row(row)\n",
    "s = tab.draw()\n",
    "import sys\n",
    "sys.stdout.write(\"\\033[F\") #back to previous line\n",
    "sys.stdout.write(\"\\033[K\") #clear line\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+\n",
      "| Gold | Silver | Bronze |\n",
      "+======+========+========+\n",
      "| 15   | 29     | 29     |\n",
      "+------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import glob\n",
    "\n",
    "#declare a set to hold all the user ids\n",
    "user_ids=set()\n",
    "files=glob.glob('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/UserData/*.json')   \n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        data=f.read()\n",
    "        user_data=json.loads(data)\n",
    "        for key in user_data:\n",
    "            #read all the keys in json and assign it to set \n",
    "            user_ids.add(user_data[key]['owner']['user_id'])\n",
    "            \n",
    "#convert the set to string\n",
    "users=str(user_ids)\n",
    "#make it a string of ids seperated by comma\n",
    "users = users.replace(\", \",\";\")\n",
    "users = users.replace(\"{\",\"\")\n",
    "users = users.replace(\"}\",\"\")\n",
    "users = users.replace(\"'\",\"\")\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/users/\"+users+\"?site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "gold=0\n",
    "silver=0\n",
    "bronze=0\n",
    "count={}\n",
    "with open('badge.json', 'w') as outfile:\n",
    "    json.dump(raw_data,outfile)\n",
    "for r in raw_data['items']:\n",
    "    if r['badge_counts']['gold']>0:\n",
    "        count['gold']=gold\n",
    "        gold+=1\n",
    "    if r['badge_counts']['silver']>0:\n",
    "        count['silver']=silver\n",
    "        silver+=1\n",
    "    if r['badge_counts']['bronze']>0:\n",
    "        count['bronze']=bronze\n",
    "        bronze+=1\n",
    "        \n",
    "plt.barh(range(len(count)), count.values(),alpha=0.5)\n",
    "plt.yticks(range(len(count)), count.keys())\n",
    "plt.xlabel('Badges')\n",
    "plt.title('Count of Users Badge wise')\n",
    "plt.show()\n",
    "\n",
    "import texttable as tt\n",
    "tab = tt.Texttable()\n",
    "header = ['Gold','Silver','Bronze']\n",
    "tab.header(header)\n",
    "row = [count['gold'],count['silver'],count['bronze']]\n",
    "tab.add_row(row)\n",
    "s = tab.draw()\n",
    "print(s)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top all time Answerers for the topic python:\n",
      "+--------------------------------------+--------------------------------------+\n",
      "|              User Name               |           Link to Profile            |\n",
      "+======================================+======================================+\n",
      "| Martijn Pieters                      | http://stackoverflow.com/users/10029 |\n",
      "|                                      | 7/martijn-pieters                    |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Alex Martelli                        | http://stackoverflow.com/users/95810 |\n",
      "|                                      | /alex-martelli                       |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| unutbu                               | http://stackoverflow.com/users/19059 |\n",
      "|                                      | 7/unutbu                             |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Ignacio Vazquez-Abrams               | http://stackoverflow.com/users/20862 |\n",
      "|                                      | /ignacio-vazquez-abrams              |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Sven Marnach                         | http://stackoverflow.com/users/27962 |\n",
      "|                                      | 7/sven-marnach                       |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| S.Lott                               | http://stackoverflow.com/users/10661 |\n",
      "|                                      | /s-lott                              |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Daniel Roseman                       | http://stackoverflow.com/users/10434 |\n",
      "|                                      | 9/daniel-roseman                     |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| abarnert                             | http://stackoverflow.com/users/90849 |\n",
      "|                                      | 4/abarnert                           |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| John La Rooy                         | http://stackoverflow.com/users/17472 |\n",
      "|                                      | 8/john-la-rooy                       |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| mgilson                              | http://stackoverflow.com/users/74885 |\n",
      "|                                      | 8/mgilson                            |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| J.F. Sebastian                       | http://stackoverflow.com/users/4279/ |\n",
      "|                                      | j-f-sebastian                        |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Ashwini Chaudhary                    | http://stackoverflow.com/users/84689 |\n",
      "|                                      | 2/ashwini-chaudhary                  |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Ned Batchelder                       | http://stackoverflow.com/users/14343 |\n",
      "|                                      | /ned-batchelder                      |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| alecxe                               | http://stackoverflow.com/users/77184 |\n",
      "|                                      | 8/alecxe                             |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Greg Hewgill                         | http://stackoverflow.com/users/893/g |\n",
      "|                                      | reg-hewgill                          |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| falsetru                             | http://stackoverflow.com/users/22256 |\n",
      "|                                      | 82/falsetru                          |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| NPE                                  | http://stackoverflow.com/users/36727 |\n",
      "|                                      | 3/npe                                |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| Joe Kington                          | http://stackoverflow.com/users/32556 |\n",
      "|                                      | 5/joe-kington                        |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| SilentGhost                          | http://stackoverflow.com/users/12855 |\n",
      "|                                      | /silentghost                         |\n",
      "+--------------------------------------+--------------------------------------+\n",
      "| e-satis                              | http://stackoverflow.com/users/9951/ |\n",
      "|                                      | e-satis                              |\n",
      "+--------------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "results = requests.get(url=\"https://api.stackexchange.com/2.2/tags/python/top-answerers/all_time?site=stackoverflow&key=Qbw)9y9ZFui61wxBzFU7mQ((\") \n",
    "raw_data=results.json() \n",
    "#print(raw_data)\n",
    "\n",
    "import json\n",
    "with open('topAnswerers.json', 'w') as outfile:\n",
    "    json.dump(raw_data,outfile)\n",
    "\n",
    "\n",
    "print('Top all time Answerers for the topic python:')    \n",
    "import texttable as tt\n",
    "tab = tt.Texttable()\n",
    "header = ['User Name','Link to Profile']\n",
    "tab.header(header)\n",
    "for d in raw_data['items']:\n",
    "    row = [d['user']['display_name'],d['user']['link']]\n",
    "    tab.add_row(row)\n",
    "s = tab.draw()\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions with top views:\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "|          Title          |          Views          |    Link to Question     |\n",
      "+=========================+=========================+=========================+\n",
      "| HDF5 - concurrency,     | 13568                   | http://stackoverflow.co |\n",
      "| compression &amp; I/O   |                         | m/questions/16628329/hd |\n",
      "| performance             |                         | f5-concurrency-         |\n",
      "|                         |                         | compression-i-o-        |\n",
      "|                         |                         | performance             |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Reading Data by         | 7                       | http://stackoverflow.co |\n",
      "| Chunking with HDF5 and  |                         | m/questions/40348945/re |\n",
      "| Pandas                  |                         | ading-data-by-chunking- |\n",
      "|                         |                         | with-hdf5-and-pandas    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas how to check     | 9                       | http://stackoverflow.co |\n",
      "| dtype for all columns   |                         | m/questions/40353079/pa |\n",
      "| in a dataframe?         |                         | ndas-how-to-check-      |\n",
      "|                         |                         | dtype-for-all-columns-  |\n",
      "|                         |                         | in-a-dataframe          |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| sshtunnel not working   | 10                      | http://stackoverflow.co |\n",
      "| in when used in a       |                         | m/questions/40328324/ss |\n",
      "| function                |                         | htunnel-not-working-in- |\n",
      "|                         |                         | when-used-in-a-function |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Prediction of Stock     | 11                      | http://stackoverflow.co |\n",
      "| Prices using ARIMA      |                         | m/questions/40353695/pr |\n",
      "|                         |                         | ediction-of-stock-      |\n",
      "|                         |                         | prices-using-arima      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How can I reshape a     | 12                      | http://stackoverflow.co |\n",
      "| Pandas DataFrame to     |                         | m/questions/40352844/ho |\n",
      "| show if certain values  |                         | w-can-i-reshape-a-      |\n",
      "| in a column are present |                         | pandas-dataframe-to-    |\n",
      "| by day?                 |                         | show-if-certain-values- |\n",
      "|                         |                         | in-a-column-are-p       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| reading a log with      | 14                      | http://stackoverflow.co |\n",
      "| dashed lines into a     |                         | m/questions/40341715/re |\n",
      "| pandas dataframe        |                         | ading-a-log-with-       |\n",
      "|                         |                         | dashed-lines-into-a-    |\n",
      "|                         |                         | pandas-dataframe        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| PermissionError: [Errno | 15                      | http://stackoverflow.co |\n",
      "| 13] Permission denied:  |                         | m/questions/40337482/pe |\n",
      "| &#39;pubmed_output&#39; |                         | rmissionerror-          |\n",
      "| (writing to csv file)   |                         | errno-13-permission-    |\n",
      "|                         |                         | denied-pubmed-output-   |\n",
      "|                         |                         | writing-to-csv-f        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas TimeGrouper in   | 16                      | http://stackoverflow.co |\n",
      "| PySpark                 |                         | m/questions/40327936/pa |\n",
      "|                         |                         | ndas-timegrouper-in-    |\n",
      "|                         |                         | pyspark                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to update the value | 17                      | http://stackoverflow.co |\n",
      "| of DatetimeIndex of a   |                         | m/questions/40340787/ho |\n",
      "| single row in a pandas  |                         | w-to-update-the-value-  |\n",
      "| DataFrame?              |                         | of-datetimeindex-of-a-  |\n",
      "|                         |                         | single-row-in-a-pandas- |\n",
      "|                         |                         | dataframe               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python/Pandas merge     | 18                      | http://stackoverflow.co |\n",
      "| issue with NaN data     |                         | m/questions/40344257/py |\n",
      "|                         |                         | thon-pandas-merge-      |\n",
      "|                         |                         | issue-with-nan-data     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to process data     | 19                      | http://stackoverflow.co |\n",
      "| with multiindex using   |                         | m/questions/40344929/ho |\n",
      "| pandas                  |                         | w-to-process-data-with- |\n",
      "|                         |                         | multiindex-using-pandas |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Plain list with heading | 20                      | http://stackoverflow.co |\n",
      "| in between into         |                         | m/questions/40332695/pl |\n",
      "| dictionary in python    |                         | ain-list-with-heading-  |\n",
      "|                         |                         | in-between-into-        |\n",
      "|                         |                         | dictionary-in-python    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| count common entries    | 46                      | http://stackoverflow.co |\n",
      "| between two string      |                         | m/questions/40326098/co |\n",
      "| variables via Python    |                         | unt-common-entries-     |\n",
      "|                         |                         | between-two-string-     |\n",
      "|                         |                         | variables-via-python    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Describe Function With  | 22                      | http://stackoverflow.co |\n",
      "| Groupby Pandas (Python  |                         | m/questions/40346436/de |\n",
      "| 3.5.1)                  |                         | scribe-function-with-   |\n",
      "|                         |                         | groupby-pandas-         |\n",
      "|                         |                         | python-3-5-1            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How do I round datetime | 1815                    | http://stackoverflow.co |\n",
      "| column to nearest       |                         | m/questions/32344533/ho |\n",
      "| quarter hour            |                         | w-do-i-round-datetime-  |\n",
      "|                         |                         | column-to-nearest-      |\n",
      "|                         |                         | quarter-hour            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How do i slice pandas   | 24                      | http://stackoverflow.co |\n",
      "| Series with             |                         | m/questions/40336262/ho |\n",
      "| DatetimeIndex and put   |                         | w-do-i-slice-pandas-    |\n",
      "| it in a DataFrame by    |                         | series-with-            |\n",
      "| rows?                   |                         | datetimeindex-and-put-  |\n",
      "|                         |                         | it-in-a-dataframe-by-   |\n",
      "|                         |                         | row                     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Login Log Off analysis  | 25                      | http://stackoverflow.co |\n",
      "| Python Pandas           |                         | m/questions/40350907/lo |\n",
      "| Timelining              |                         | gin-log-off-analysis-   |\n",
      "|                         |                         | python-pandas-          |\n",
      "|                         |                         | timelining              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas: sorting a       | 26                      | http://stackoverflow.co |\n",
      "| dataframe in subgroups, |                         | m/questions/40348116/pa |\n",
      "| issue with sorting      |                         | ndas-sorting-a-         |\n",
      "| equal values            |                         | dataframe-in-subgroups- |\n",
      "|                         |                         | issue-with-sorting-     |\n",
      "|                         |                         | equal-values            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to use groupby      | 27                      | http://stackoverflow.co |\n",
      "| method combine several  |                         | m/questions/40351635/ho |\n",
      "| (use slice?) columns or |                         | w-to-use-groupby-       |\n",
      "| rows?                   |                         | method-combine-several- |\n",
      "|                         |                         | use-slice-columns-or-   |\n",
      "|                         |                         | rows                    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Why do I get 0 when     | 28                      | http://stackoverflow.co |\n",
      "| dividing two numbers?   |                         | m/questions/40354235/wh |\n",
      "|                         |                         | y-do-i-get-0-when-      |\n",
      "|                         |                         | dividing-two-numbers    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas                  | 29                      | http://stackoverflow.co |\n",
      "| &quot;diff()&quot; with |                         | m/questions/40348541/pa |\n",
      "| string                  |                         | ndas-diff-with-string   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| idxmax() equality with  | 31                      | http://stackoverflow.co |\n",
      "| pandas                  |                         | m/questions/40331738/id |\n",
      "|                         |                         | xmax-equality-with-     |\n",
      "|                         |                         | pandas                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas performance      | 33                      | http://stackoverflow.co |\n",
      "| varies between mac and  |                         | m/questions/40345556/pa |\n",
      "| linux                   |                         | ndas-performance-       |\n",
      "|                         |                         | varies-between-mac-and- |\n",
      "|                         |                         | linux                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| List of diverse lists   | 34                      | http://stackoverflow.co |\n",
      "| to sorted pandas data   |                         | m/questions/40346400/li |\n",
      "| frame                   |                         | st-of-diverse-lists-to- |\n",
      "|                         |                         | sorted-pandas-data-     |\n",
      "|                         |                         | frame                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Count instances based   | 35                      | http://stackoverflow.co |\n",
      "| on criteria with        |                         | m/questions/40349499/co |\n",
      "| groupby()               |                         | unt-instances-based-on- |\n",
      "|                         |                         | criteria-with-groupby   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Simple Logistic         | 40                      | http://stackoverflow.co |\n",
      "| Regression Error in     |                         | m/questions/40051478/si |\n",
      "| Python                  |                         | mple-logistic-          |\n",
      "|                         |                         | regression-error-in-    |\n",
      "|                         |                         | python                  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Multiple Categorical    | 42                      | http://stackoverflow.co |\n",
      "| values for a single     |                         | m/questions/40331558/mu |\n",
      "| feature how to convert  |                         | ltiple-categorical-     |\n",
      "| them to binary using    |                         | values-for-a-single-    |\n",
      "| python                  |                         | feature-how-to-convert- |\n",
      "|                         |                         | them-to-binary-u        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Tidy data from          | 44                      | http://stackoverflow.co |\n",
      "| multilevel Excel file   |                         | m/questions/40319532/ti |\n",
      "| via pandas              |                         | dy-data-from-           |\n",
      "|                         |                         | multilevel-excel-file-  |\n",
      "|                         |                         | via-pandas              |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Loading a very large    | 174                     | http://stackoverflow.co |\n",
      "| txt file and taking     |                         | m/questions/34686216/lo |\n",
      "| transpose               |                         | ading-a-very-large-txt- |\n",
      "|                         |                         | file-and-taking-        |\n",
      "|                         |                         | transpose               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How to add a bolean     | 47                      | http://stackoverflow.co |\n",
      "| series to a new column  |                         | m/questions/40302071/ho |\n",
      "| in df2 IF multiple      |                         | w-to-add-a-bolean-      |\n",
      "| conditions in df1 are   |                         | series-to-a-new-column- |\n",
      "| met (incl. DATETIME)?   |                         | in-df2-if-multiple-     |\n",
      "|                         |                         | conditions-in-df1       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Linear algebra in Numpy | 49                      | http://stackoverflow.co |\n",
      "|                         |                         | m/questions/40345334/li |\n",
      "|                         |                         | near-algebra-in-numpy   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Finding the largest N   | 51                      | http://stackoverflow.co |\n",
      "| integrals in a time     |                         | m/questions/40341783/fi |\n",
      "| series with Python      |                         | nding-the-largest-n-    |\n",
      "|                         |                         | integrals-in-a-time-    |\n",
      "|                         |                         | series-with-python      |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Get the counts and      | 53                      | http://stackoverflow.co |\n",
      "| unique counts of every  |                         | m/questions/40348733/ge |\n",
      "| columns in python       |                         | t-the-counts-and-       |\n",
      "|                         |                         | unique-counts-of-every- |\n",
      "|                         |                         | columns-in-python       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| How save an string      | 54                      | http://stackoverflow.co |\n",
      "| output after a for loop |                         | m/questions/39857297/ho |\n",
      "| in python with pandas   |                         | w-save-an-string-       |\n",
      "| and csv modules?        |                         | output-after-a-for-     |\n",
      "|                         |                         | loop-in-python-with-    |\n",
      "|                         |                         | pandas-and-csv-modules  |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Python Pandas: How can  | 56                      | http://stackoverflow.co |\n",
      "| I group by and assign   |                         | m/questions/36063251/py |\n",
      "| an id to all the items  |                         | thon-pandas-how-can-i-  |\n",
      "| in a group?             |                         | group-by-and-assign-an- |\n",
      "|                         |                         | id-to-all-the-items-in- |\n",
      "|                         |                         | a-group                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Slow performance -      | 57                      | http://stackoverflow.co |\n",
      "| Python (code)           |                         | m/questions/40347691/sl |\n",
      "|                         |                         | ow-performance-python-  |\n",
      "|                         |                         | code                    |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| TypeError when          | 64                      | http://stackoverflow.co |\n",
      "| converting Pandas to    |                         | m/questions/39862211/ty |\n",
      "| Spark                   |                         | peerror-when-           |\n",
      "|                         |                         | converting-pandas-to-   |\n",
      "|                         |                         | spark                   |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas sorting          | 1735                    | http://stackoverflow.co |\n",
      "| pivot_table or grouping |                         | m/questions/14085517/pa |\n",
      "| dataframe?              |                         | ndas-sorting-pivot-     |\n",
      "|                         |                         | table-or-grouping-      |\n",
      "|                         |                         | dataframe               |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Pandas: apply different | 468                     | http://stackoverflow.co |\n",
      "| functions to different  |                         | m/questions/26434123/pa |\n",
      "| columns                 |                         | ndas-apply-different-   |\n",
      "|                         |                         | functions-to-different- |\n",
      "|                         |                         | columns                 |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| pandas: selecting array | 1888                    | http://stackoverflow.co |\n",
      "| of index labels with    |                         | m/questions/19844985/pa |\n",
      "| .loc                    |                         | ndas-selecting-array-   |\n",
      "|                         |                         | of-index-labels-with-   |\n",
      "|                         |                         | loc                     |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| daily data, resample    | 354                     | http://stackoverflow.co |\n",
      "| every 3 days, calculate |                         | m/questions/40209520/da |\n",
      "| over trailing 5 days    |                         | ily-data-resample-      |\n",
      "| efficiently             |                         | every-3-days-calculate- |\n",
      "|                         |                         | over-trailing-5-days-   |\n",
      "|                         |                         | efficiently             |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Comparing rows of       | 7399                    | http://stackoverflow.co |\n",
      "| pandas dataframe (rows  |                         | m/questions/16533421/co |\n",
      "| have some overlapping   |                         | mparing-rows-of-pandas- |\n",
      "| values)                 |                         | dataframe-rows-have-    |\n",
      "|                         |                         | some-overlapping-values |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Filtering all rows with | 7272                    | http://stackoverflow.co |\n",
      "| NaT in a column in      |                         | m/questions/23747451/fi |\n",
      "| Dataframe python        |                         | ltering-all-rows-with-  |\n",
      "|                         |                         | nat-in-a-column-in-     |\n",
      "|                         |                         | dataframe-python        |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Move columns within     | 1518                    | http://stackoverflow.co |\n",
      "| Pandas DATA FRAME       |                         | m/questions/33216180/mo |\n",
      "|                         |                         | ve-columns-within-      |\n",
      "|                         |                         | pandas-data-frame       |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| how to use pandas       | 506                     | http://stackoverflow.co |\n",
      "| filter with IQR?        |                         | m/questions/34782063/ho |\n",
      "|                         |                         | w-to-use-pandas-filter- |\n",
      "|                         |                         | with-iqr                |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "| Aggregating on 5 minute | 21                      | http://stackoverflow.co |\n",
      "| windows in pyspark      |                         | m/questions/40341213/ag |\n",
      "|                         |                         | gregating-on-5-minute-  |\n",
      "|                         |                         | windows-in-pyspark      |\n",
      "+-------------------------+-------------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import glob\n",
    "\n",
    "#declare a set to hold all the user ids\n",
    "views={}\n",
    "files=glob.glob('C:/Fall 2016/Data Analysis using Python/Python-Assignments/Midterm/UserData/*.json')   \n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        data=f.read()\n",
    "        user_data=json.loads(data)\n",
    "        for key in user_data:\n",
    "            #read all the keys in json and assign it to set \n",
    "            views[user_data[key]['view_count']]={}\n",
    "            views[user_data[key]['view_count']]['title']=user_data[key]['title']\n",
    "            views[user_data[key]['view_count']]['link']=user_data[key]['link']\n",
    "sorted_views=sorted(views.items(),reverse=True)\n",
    "v=dict(sorted_views)\n",
    "print('Questions with top views:') \n",
    "import texttable as tt\n",
    "tab = tt.Texttable()\n",
    "header = ['Title','Views','Link to Question']\n",
    "tab.header(header)\n",
    "for k in v:\n",
    "    row = [v[k]['title'],k,v[k]['link']]\n",
    "    tab.add_row(row)\n",
    "s = tab.draw()\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
